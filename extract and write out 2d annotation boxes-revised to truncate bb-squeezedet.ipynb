{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "created by @asha\n",
    "march 8th 2019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v0.1 ...\n",
      "23 category,\n",
      "8 attribute,\n",
      "5 visibility,\n",
      "6975 instance,\n",
      "12 sensor,\n",
      "1200 calibrated_sensor,\n",
      "304715 ego_pose,\n",
      "12 log,\n",
      "100 scene,\n",
      "3977 sample,\n",
      "304715 sample_data,\n",
      "99952 sample_annotation,\n",
      "12 map,\n",
      "Done loading in 9.8 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "# Let's start by initializing the database\n",
    "%matplotlib inline\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "import numpy as np\n",
    "\n",
    "nusc = NuScenes(version='v0.1', dataroot='data/nuscenes', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories that are annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human.pedestrian.adult\n",
      "human.pedestrian.child\n",
      "human.pedestrian.wheelchair\n",
      "human.pedestrian.stroller\n",
      "human.pedestrian.personal_mobility\n",
      "human.pedestrian.police_officer\n",
      "human.pedestrian.construction_worker\n",
      "animal\n",
      "vehicle.car\n",
      "vehicle.motorcycle\n",
      "vehicle.bicycle\n",
      "vehicle.bus.bendy\n",
      "vehicle.bus.rigid\n",
      "vehicle.truck\n",
      "vehicle.construction\n",
      "vehicle.emergency.ambulance\n",
      "vehicle.emergency.police\n",
      "vehicle.trailer\n",
      "movable_object.barrier\n",
      "movable_object.trafficcone\n",
      "movable_object.pushable_pullable\n",
      "movable_object.debris\n",
      "static_object.bicycle_rack\n"
     ]
    }
   ],
   "source": [
    "# The NuScenes class holds several tables. Each table is a list of records, and each record is a dictionary. \n",
    "# For example the first record of the category table is stored at\n",
    "\n",
    "#nusc.category[0]['name']\n",
    "\n",
    "#these are the categories available\n",
    "cat = []\n",
    "for i in range(len(nusc.category)):\n",
    "    print(nusc.category[i]['name'])\n",
    "    cat.append(nusc.category[i]['name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classes that we are detecting :\n",
    "\n",
    "We merge adult, child, police officer, construction worker into a single class called pedestrian\n",
    "We are detecting: \n",
    "- pedestrian\n",
    "- car \n",
    "- bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['human.pedestrian.adult', 'human.pedestrian.child','human.pedestrian.police_officer','human.pedestrian.construction_worker','vehicle.car','vehicle.bicycle']\n",
    "pedestrians = ['human.pedestrian.adult', 'human.pedestrian.child','human.pedestrian.police_officer','human.pedestrian.construction_worker'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples\n",
      "3977\n"
     ]
    }
   ],
   "source": [
    "print('Total number of samples')\n",
    "print(len(nusc.sample))\n",
    "\n",
    "total_no_of_samples = len(nusc.sample)\n",
    "\n",
    "#print('Total number of images')\n",
    "#print(len(nusc.sample*6)) #6 different cameras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined the following function:\n",
    "\n",
    "- get_sample_data (edit of nutonomy's original nusc.get_sample_data)\n",
    "        \n",
    "        input:(nusc, sample_data_token)\n",
    "        output:path to the data, lists of 3d bounding boxes in the image (in camera coordinates), \n",
    "        annotation token of annotations in the image, intrinsic matrix of the camera)\n",
    "        \n",
    "\n",
    "- threeD_to_2D\n",
    "         \n",
    "        input: (box (camera coordinates),intrinsic matrix))\n",
    "        output : corners of the 2d bounding box in image plane\n",
    "\n",
    "- all_3d_to_2d(boxes,anns,intrinsic)\n",
    "\n",
    "        input : boxes in camera coordinates, list of annotation tokens of annotations in the image, \n",
    "        intrinsic matrix\n",
    "        output: x_min,x_max,y_min,y_max,width,height of the 2D boundings boxes of objects that are\n",
    "        more than 40% visible in panoramic view of all cameras, also ensures that the center of the \n",
    "        bounding boxes falls inside the image\n",
    "\n",
    "- extract_bounding_box(i):\n",
    "        \n",
    "        input: sample number\n",
    "        output: min x, max x, min y max y, width and height of bounding box in image coordinates \n",
    "        2d bounding box of objects which are 40% visible in panoramic view of all cameras and center \n",
    "        falls witin the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion\n",
    "from nuscenes.utils.data_classes import Box\n",
    "from nuscenes.utils.geometry_utils import quaternion_slerp, box_in_image, BoxVisibility\n",
    "import numpy as np\n",
    "def get_sample_data(nusc_object, sample_data_token, box_vis_level=BoxVisibility.ANY, selected_anntokens=None):\n",
    "    \"\"\"\n",
    "    Returns the data path as well as all annotations related to that sample_data(single image).\n",
    "    Note that the boxes are transformed into the current sensor's coordinate frame.\n",
    "    :param sample_data_token: <str>. Sample_data token(image token).\n",
    "    :param box_vis_level: <BoxVisibility>. If sample_data is an image, this sets required visibility for boxes.\n",
    "    :param selected_anntokens: [<str>]. If provided only return the selected annotation.\n",
    "    :return: (data_path <str>, boxes [<Box>], camera_intrinsic <np.array: 3, 3>)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve sensor & pose records\n",
    "    sd_record = nusc_object.get('sample_data', sample_data_token)\n",
    "    cs_record = nusc_object.get('calibrated_sensor', sd_record['calibrated_sensor_token'])\n",
    "    sensor_record = nusc_object.get('sensor', cs_record['sensor_token'])\n",
    "    pose_record = nusc_object.get('ego_pose', sd_record['ego_pose_token'])\n",
    "\n",
    "    sample_record = nusc_object.get('sample',sd_record['sample_token'])\n",
    "    data_path = nusc_object.get_sample_data_path(sample_data_token)\n",
    "\n",
    "    if sensor_record['modality'] == 'camera':\n",
    "        cam_intrinsic = np.array(cs_record['camera_intrinsic'])\n",
    "        imsize = (sd_record['width'], sd_record['height'])\n",
    "    else:\n",
    "        cam_intrinsic = None\n",
    "        imsize = None\n",
    "\n",
    "    # Retrieve all sample annotations and map to sensor coordinate system.\n",
    "    if selected_anntokens is not None:\n",
    "        boxes = list(map(nusc_object.get_box, selected_anntokens))\n",
    "    else:\n",
    "        boxes = nusc_object.get_boxes(sample_data_token)\n",
    "        selected_anntokens = sample_record['anns']\n",
    "\n",
    "    # Make list of Box objects including coord system transforms.\n",
    "    box_list = []\n",
    "    ann_list = []\n",
    "    for box,ann in zip(boxes,selected_anntokens):\n",
    "\n",
    "        # Move box to ego vehicle coord system\n",
    "        box.translate(-np.array(pose_record['translation']))\n",
    "        box.rotate(Quaternion(pose_record['rotation']).inverse)\n",
    "\n",
    "        #  Move box to sensor coord system\n",
    "        box.translate(-np.array(cs_record['translation']))\n",
    "        box.rotate(Quaternion(cs_record['rotation']).inverse)\n",
    "\n",
    "        if sensor_record['modality'] == 'camera' and not \\\n",
    "                box_in_image(box, cam_intrinsic, imsize, vis_level=box_vis_level):\n",
    "            continue\n",
    "\n",
    "        box_list.append(box)\n",
    "        ann_list.append(ann)\n",
    "    #this is for a single sample image\n",
    "    return data_path, box_list, ann_list, cam_intrinsic #single image info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDIT THISL:\n",
    "    KEEP THIS LINE : if visibility > 1: #more than 40% visible in the panoramic view of the the cameras\n",
    "\n",
    "    that's to make sure that bounding box is only made for object whose visibity is more than 40%\n",
    "    \n",
    "    \n",
    "    you can edit after that line, under else, just append the visibility token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threeD_2_twoD(boxsy,intrinsic): #input is a single annotation box\n",
    "    '''\n",
    "    given annotation boxes and intrinsic camera matrix\n",
    "    outputs the 2d bounding box coordinates as a list (all annotations for a particular sample image)\n",
    "    '''\n",
    "    corners = boxsy.corners()\n",
    "    x = corners[0,:]\n",
    "    y = corners[1,:]\n",
    "    z = corners[2,:]\n",
    "    x_y_z = np.array((x,y,z))\n",
    "    orthographic = np.dot(intrinsic,x_y_z)\n",
    "    perspective_x = orthographic[0]/orthographic[2]\n",
    "    perspective_y = orthographic[1]/orthographic[2]\n",
    "    perspective_z = orthographic[2]/orthographic[2]\n",
    "    \n",
    "    min_x = np.min(perspective_x)\n",
    "    max_x = np.max(perspective_x)\n",
    "    min_y = np.min(perspective_y)\n",
    "    max_y = np.max(perspective_y)\n",
    "    \n",
    "\n",
    "    \n",
    "    return min_x,max_x,min_y,max_y\n",
    "\n",
    "\n",
    "\n",
    "def all_3d_to_2d(boxes,anns,intrinsic): #input 3d boxes, annotation key lists, intrinsic matrix (one image)\n",
    "    x_min=[]\n",
    "    x_max=[]\n",
    "    y_min=[]\n",
    "    y_max =[]\n",
    "    width=[]\n",
    "    height=[]\n",
    "    objects_detected =[]\n",
    "    orig_objects_detected =[]\n",
    "    \n",
    "   \n",
    "    for j in range(len(boxes)): #iterate through boxes\n",
    "        box=boxes[j]\n",
    "        \n",
    "        if box.name in classes: #if the box.name is in the classes we want to detect\n",
    "        \n",
    "            if box.name in pedestrians: \n",
    "                orig_objects_detected.append(\"pedestrian\")\n",
    "            elif box.name == \"vehicle.car\":\n",
    "                orig_objects_detected.append(\"car\")\n",
    "            else:\n",
    "                orig_objects_detected.append(\"cyclist\")\n",
    "            #print(box)\n",
    "            \n",
    "            visibility = nusc.get('sample_annotation', '%s' %anns[j])['visibility_token'] #give annotation key\n",
    "            visibility = int(visibility)\n",
    "\n",
    "            \n",
    "            if visibility > 1: #more than 40% visible in the panoramic view of the the cameras\n",
    "\n",
    "                    \n",
    "                center = box.center #get boxe's center\n",
    "\n",
    "                center = np.dot(intrinsic,center)\n",
    "                center_point = center/(center[2]) #convert center point into image plane\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if center_point[0] <-100 or center_point[0] > 1700 or center_point[1] <-100 or center_point[1] >1000:\n",
    "                    #if center of bounding box is outside of the image, do not annotate\n",
    "                    pass\n",
    "                \n",
    "                else:\n",
    "                    min_x, max_x, min_y, max_y = threeD_2_twoD(box,intrinsic) #converts box into image plane\n",
    "                    w = max_x - min_x\n",
    "                    h = max_y - min_y\n",
    "        \n",
    "        \n",
    "                    x_min.append(min_x)\n",
    "                    x_max.append(max_x)\n",
    "                    y_min.append(min_y)\n",
    "                    y_max.append(max_y)\n",
    "                    width.append(w)\n",
    "                    height.append(h)\n",
    "                    if box.name in pedestrians: \n",
    "                        objects_detected.append(\"pedestrian\")\n",
    "                    elif box.name == \"vehicle.car\":\n",
    "                        objects_detected.append(\"car\")\n",
    "                    else:\n",
    "                        objects_detected.append(\"cyclist\")\n",
    "                    \n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return x_min,x_max,y_min,y_max,width,height,objects_detected,orig_objects_detected #for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_box(i,camera_name): #give a single sample number and camera name\n",
    "    \n",
    "    '''\n",
    "    input sample number i, camera name\n",
    "    outputs min x, max x, min y max y, width and height of bounding box in image coordinates\n",
    "    2d bounding box\n",
    "    options for camera name : CAM_FRONT, CAM_FRONT_RIGHT, CAM_FRONT_LEFT, CAM_BACK, CAM_BACK_RIGHT,CAM_BACK_LEFT\n",
    "    '''\n",
    "    \n",
    "    nusc.sample[i] #one image\n",
    "    \n",
    "    camera_token = nusc.sample[i]['data']['%s' %camera_name] #one camera, get the camera token \n",
    "\n",
    "    path, boxes, anns, intrinsic_matrix = get_sample_data(nusc,'%s' %camera_token) #gets data for one image\n",
    "    \n",
    "    x_min, x_max,y_min,y_max,width,height, objects_detected,orig_objects_detected = all_3d_to_2d(boxes,anns, intrinsic_matrix)\n",
    "    \n",
    "    return x_min, x_max, y_min, y_max, width, height, path, boxes,intrinsic_matrix, objects_detected,orig_objects_detected\n",
    "    #info for a single image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create target Directory if don't exist\n",
    "import os.path\n",
    "def create_annotation_directory(camera):\n",
    "    current_dir =os.getcwd()\n",
    "    #current_dir =\"%s/annotation\" %pwd\n",
    "    dirName =\"%s/annotation/%s_anno\" %(current_dir,camera)\n",
    "    if not os.path.exists(dirName):\n",
    "        os.makedirs(dirName)\n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    else:    \n",
    "        print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree as ET\n",
    "def write_xml_annotation(x_min,x_max,y_min,y_max,width,height,path,boxes,objects_detected): #single image info\n",
    "    #detected_items =[]\n",
    "    #import xml.etree.cElementTree as ET\n",
    "    path_split = path.split(\"/\")\n",
    "    full_image_name = path_split[-1]\n",
    "    name =full_image_name.split(\".\")[0]\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "\n",
    "\n",
    "    ET.SubElement(root, \"folder\").text = \"%s\" %camera\n",
    "    ET.SubElement(root, \"filename\").text = \"%s\" %full_image_name\n",
    "    ET.SubElement(root, \"path\").text = \"%s\" %path\n",
    "\n",
    "    source = ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"nuTonomy-nuscenes\"\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(size, \"width\").text=\"1600\"\n",
    "    ET.SubElement(size,\"height\").text=\"900\"\n",
    "    ET.SubElement(size,\"depth\").text=\"3\"\n",
    "    ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "    for j in range(len(objects_detected)): #\n",
    "        \n",
    "        flag_x = 0\n",
    "        flag_y = 0\n",
    "        \n",
    "        ob= ET.SubElement(root, \"object\")\n",
    "        ET.SubElement(ob,\"name\").text=\"%s\" %objects_detected[j]\n",
    "        ET.SubElement(ob,\"pose\").text=\"Unspecified\"\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        write out truncated boxes\n",
    "        '''\n",
    "        \n",
    "        if x_min[j] < 0:\n",
    "            x_minsy = 0\n",
    "            flag_x =1\n",
    "            \n",
    "        else:\n",
    "            x_minsy = x_min[j]\n",
    "            \n",
    "        if y_min[j] <0:\n",
    "            y_minsy = 0\n",
    "            flag_y =1\n",
    "            \n",
    "        else:\n",
    "            y_minsy = y_min[j]\n",
    "            \n",
    "        if x_max[j] > 1600:\n",
    "            x_maxsy = 1600\n",
    "            flag_x = 1\n",
    "            \n",
    "        else:\n",
    "            x_maxsy = x_max[j]\n",
    "            \n",
    "        if y_max[j] >900:\n",
    "            y_maxsy = 900\n",
    "            flag_y = 1\n",
    "            \n",
    "        else:\n",
    "            y_maxsy = y_max[j]\n",
    "            \n",
    "            \n",
    "        if flag_x == 1 or flag_y ==1:\n",
    "            ET.SubElement(ob, \"truncated\").text=\"1\"\n",
    "            \n",
    "        else:\n",
    "            ET.SubElement(ob, \"truncated\").text=\"0\"\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        ET.SubElement(ob, \"difficult\").text=\"0\"\n",
    "\n",
    "        bb = ET.SubElement(ob,\"bndbox\")\n",
    "        \n",
    "        \n",
    "        ET.SubElement(bb,\"xmin\").text=\"%s\" %x_minsy\n",
    "        ET.SubElement(bb,\"ymin\").text=\"%s\" %y_minsy\n",
    "        ET.SubElement(bb,\"xmax\").text=\"%s\" %x_maxsy\n",
    "        ET.SubElement(bb,\"ymax\").text=\"%s\" %y_maxsy\n",
    "        \n",
    " \n",
    "    filename = \"%s/%s.xml\" %(dirName,name)\n",
    "    tree = ET.ElementTree(root)\n",
    "    #tree.write(\"%s/%s.xml\" %(dirName,name),pretty_print=True)\n",
    "    tree.write(\"%s\" %filename, pretty_print=True)\n",
    "    \n",
    "    return filename #file a single file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename,dirName): #extract info from a single file\n",
    "\n",
    "    objects_detected =[]\n",
    "    x_min=[]\n",
    "    x_max=[]\n",
    "    y_min=[]\n",
    "    y_max=[]\n",
    "    width=[]\n",
    "    height=[]\n",
    "\n",
    "\n",
    "    \n",
    "    tree = ET.parse('%s' %(filename))  \n",
    "    root = tree.getroot()\n",
    "\n",
    "\n",
    "\n",
    "    for objs in root.findall('object'):\n",
    "        #print(\"yolo\")\n",
    "        name = objs.find('name').text\n",
    "        objects_detected.append(name)\n",
    "    \n",
    "        for bbs in objs.findall('bndbox'):\n",
    "        \n",
    "            xmin = bbs.find('xmin').text\n",
    "            x_min.append(float(xmin))\n",
    "        \n",
    "            xmax = bbs.find('xmax').text\n",
    "            x_max.append(float(xmax))\n",
    "        \n",
    "            ymin = bbs.find('ymin').text\n",
    "            y_min.append(float(ymin))\n",
    "        \n",
    "            ymax = bbs.find('ymax').text\n",
    "            y_max.append(float(ymax))\n",
    "        \n",
    "        \n",
    "            w = float(xmax) - float(xmin)\n",
    "            h = float(ymax) - float(ymin)\n",
    "        \n",
    "            width.append(w)\n",
    "            height.append(h)\n",
    "\n",
    "    return width,height,objects_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAM_FRONT_RIGHT\n",
      "Directory  /Volumes/Luthor/nutonomy/nuscenes-devkit-master/python-sdk/annotation/CAM_FRONT_RIGHT_anno  already exists\n",
      "[]\n",
      "[]\n",
      "/Volumes/Luthor/nutonomy/nuscenes-devkit-master/python-sdk/annotation/CAM_FRONT_RIGHT_anno/n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915629419956.xml\n",
      "357\n",
      "['pedestrian']\n",
      "[329.3210103560269]\n",
      "/Volumes/Luthor/nutonomy/nuscenes-devkit-master/python-sdk/annotation/CAM_FRONT_RIGHT_anno/n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915629419956.xml\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "#camera_names =['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT', 'CAM_BACK_LEFT']\n",
    "camera_names=['CAM_FRONT_RIGHT']\n",
    "i = 0\n",
    "detected_items =[]\n",
    "orig_detected_items=[]\n",
    "obs = []\n",
    "\n",
    "file=[]\n",
    "\n",
    "for camera in camera_names: #iterate through all cameras\n",
    "    print(camera)\n",
    "    create_annotation_directory(camera)\n",
    "    current_dir =os.getcwd()\n",
    "    dirName =\"%s/annotation/%s_anno\" %(current_dir,camera) #current directory's name\n",
    "    #we are looking at one camera now\n",
    "    for sample_number in range(total_no_of_samples):#look at a single image\n",
    "        #print(sample_number)\n",
    "        #get in for a single image\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x_min, x_max,y_min,y_max,width,height, path, boxes, intrinsic_matrix,objects_detected,orig_objects_detected = extract_bounding_box(sample_number, '%s' %camera) \n",
    "        \n",
    "        '''\n",
    "        if len(objects_detected) ==0:\n",
    "            \n",
    "                #print('Katie')\n",
    "                path_split = path.split(\"/\")\n",
    "                full_image_name = path_split[-1]\n",
    "                name =full_image_name.split(\".\")[0]\n",
    "                filename = \"%s/%s.xml\" %(dirName,name)\n",
    "                fname=\"%s.xml\" %name\n",
    "                if fname =='n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915629419956.xml':\n",
    "                    print(objects_detected)\n",
    "                    print(x_min)\n",
    "                    print(filename)\n",
    "                    print(sample_number)\n",
    "                    \n",
    "                    \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        path_split = path.split(\"/\")\n",
    "        full_image_name = path_split[-1]\n",
    "        name =full_image_name.split(\".\")[0]\n",
    "        filename = \"%s/%s.xml\" %(dirName,name)\n",
    "        fname=\"%s.xml\" %name\n",
    "        if fname =='n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915629419956.xml':\n",
    "            print(objects_detected)\n",
    "            print(x_min)\n",
    "            print(filename)\n",
    "            print(sample_number)\n",
    "                    \n",
    "                \n",
    "                #with open(\"images_with_no_annotations.txt\", \"a\") as file_list:\n",
    "                    #file_list.write(filename)\n",
    "                    #file_list.write('\\n')\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #write_xml_annotation(x_min,x_max,y_min,y_max,width,height,path,boxes,objects_detected)\n",
    "         \n",
    "        #if sample_number !=0 :\n",
    "            #if file[-1] == filename:\n",
    "                #print(sample_number)\n",
    "        \n",
    "        #file.append(filename)\n",
    "        \n",
    "\n",
    "        #print\n",
    "        #print(filename)\n",
    "        \n",
    "        #widthsy, heightsy, objects_detectedsy = extract_data(filename,dirName)\n",
    "        \n",
    "        #assert objects_detected == objects_detectedsy\n",
    "\n",
    "        \n",
    "        \n",
    "        #detected_items = detected_items + objects_detected\n",
    "        #orig_detected_items= orig_detected_items + orig_objects_detected\n",
    "        #obs = obs + objects_detectedsy\n",
    "        #if len(x_min) ==0:\n",
    "            \n",
    "            #i = i+1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(obs))\n",
    "print(len(orig_detected_items))\n",
    "\n",
    "print(len(file))\n",
    "\n",
    "unique = list(set(file))\n",
    "print(len(unique))\n",
    "\n",
    "print('total number of files')\n",
    "3962*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(file))\n",
    "#print(len(unique))\n",
    "\n",
    "for i in range(len(file)):\n",
    "    check = file[i]\n",
    "    \n",
    "    for j in range(len(file)):\n",
    "        if j !=i :\n",
    "            if check == file[j]:\n",
    "                print(i)\n",
    "                print(j)\n",
    "                print('katie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import listdir\n",
    "import xml.etree.ElementTree as ET  \n",
    "camera_names =['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_FRONT_LEFT', 'CAM_BACK', 'CAM_BACK_RIGHT', 'CAM_BACK_LEFT']\n",
    "\n",
    "def list_of_files(camera):\n",
    "    current_dir =os.getcwd()\n",
    "    #current_dir =\"%s/annotation\" %pwd\n",
    "    \n",
    "    dirName =\"%s/annotation/%s_anno\" %(current_dir,camera)\n",
    "    files = os.listdir(dirName)\n",
    "    \n",
    "    return files, dirName, current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_objects_detected =[]\n",
    "for camera in camera_names:\n",
    "    files, dirName,current_dir = list_of_files(camera)\n",
    "    print(dirName)\n",
    "    \n",
    "    for f in files:\n",
    "        name_of_file = '%s/%s' %(dirName, f)\n",
    "        #print(name_of_file)\n",
    "        w,h,od = extract_data(name_of_file,dirName)\n",
    "        total_objects_detected = total_objects_detected + od\n",
    "        #print(od)\n",
    "        #print(od)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(total_objects_detected))\n",
    "print(len(detected_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orig_detected_items.count('car'))\n",
    "print(orig_detected_items.count('pedestrian'))\n",
    "print(orig_detected_items.count('cyclist'))\n",
    "\n",
    "\n",
    "add = orig_detected_items.count('car') + orig_detected_items.count('pedestrian') + orig_detected_items.count('cyclist')\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(detected_items))\n",
    "print('Total number of car annotations:')\n",
    "print(detected_items.count('car'))\n",
    "print('Total number of pedestrian annotations')\n",
    "print(detected_items.count('pedestrian'))\n",
    "print('Total number of cyclist annotations')\n",
    "print(detected_items.count('cyclist'))\n",
    "\n",
    "add = detected_items.count('car') + detected_items.count('pedestrian') + detected_items.count('cyclist')\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "im = np.array(Image.open('/Volumes/Luthor/nutonomy/nuscenes-devkit-master/python-sdk/%s' %path), dtype=np.uint8)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "# Create figure and axes\n",
    "\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(im)\n",
    "#\n",
    "\n",
    "#print(x)\n",
    "#print(y)\n",
    "#print(width)\n",
    "#print(height)\n",
    "#print(center_point[0])\n",
    "#print(center_point[1])\n",
    "\n",
    "#width = max_x-min_x\n",
    "#height = max_y-min_y\n",
    "#for i in range(len(perspective_x)):\n",
    "#ax.plot(center_point[0], center_point[1], marker ='o', color='b', markersize =30)\n",
    "#ax.plot(perspective_x[i], perspective_y[i], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(r2c2[0], r2c2[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(min_x, min_y, marker ='o', color='b', markersize =10)\n",
    "#ax.plot(max_x, max_y, marker ='o', color='b', markersize =10)\n",
    "\n",
    "for i in range(len(x_min)):\n",
    "    if objects_detected[i] =='pedestrian':\n",
    "        col = 'red'\n",
    "    elif objects_detected[i] =='car':\n",
    "        col ='green'\n",
    "    else:\n",
    "        col= 'blue'\n",
    "    rect = patches.Rectangle((x_min[i],y_min[i]),width[i],height[i],linewidth=2,edgecolor='%s' %col,facecolor='none')\n",
    "#ax.plot(k3[0], k3[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(k4[0], k4[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(k5[0], k5[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(k6[0], k6[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(k7[0], k7[1], marker ='o', color='b', markersize =10)\n",
    "#ax.plot(k8[0], k8[1], marker ='o', color='b', markersize =10)\n",
    "    \n",
    "#rect = patches.Rectangle((x,y),width,height,linewidth=1,edgecolor='blue',facecolor='none')\n",
    "\n",
    "# Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "plt.savefig('foo.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d render with original bounding boxes\n",
    "#343\n",
    "#369\n",
    "\n",
    "#383\n",
    "#357\n",
    "sample_number =348\n",
    "camera = 'CAM_FRONT_RIGHT'\n",
    "my_sample = nusc.sample[sample_number]\n",
    "nusc.render_sample_data(my_sample['data']['%s' %camera])\n",
    "print(my_sample)\n",
    "print('this is the path')\n",
    "\n",
    "nusc.get('sample_data', 'bde261e2ea904fcd86cef6e007bdfdb4')\n",
    "\n",
    "\n",
    "f1= 'samples/CAM_FRONT_RIGHT/n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915624869956.jpg'\n",
    "f2 ='samples/CAM_FRONT_RIGHT/n008-2018-05-21-11-06-59-0400__CAM_FRONT_RIGHT__1526915624869956.jpg'\n",
    "\n",
    "if f1 ==f2:\n",
    "    print('katie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number =374\n",
    "camera = 'CAM_FRONT_RIGHT'\n",
    "my_sample = nusc.sample[sample_number]\n",
    "nusc.render_sample_data(my_sample['data']['%s' %camera])\n",
    "print(my_sample)\n",
    "\n",
    "#'5eedbe17cf2f44e2829567eeeb12f569'\n",
    "\n",
    "print('this is the path')\n",
    "\n",
    "nusc.get('sample_data', '2cab2f94315e47eea4e4409d7906db6b')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xml.etree.cElementTree as ET\n",
    "from lxml import etree as ET\n",
    "root = ET.Element(\"annotation\")\n",
    "\n",
    "\n",
    "ET.SubElement(root, \"folder\").text = \"captures_vlc\"\n",
    "ET.SubElement(root, \"filename\").text = \"katie.jpg\"\n",
    "ET.SubElement(root, \"path\").text = \"katie.jpg\"\n",
    "\n",
    "source = ET.SubElement(root, \"source\")\n",
    "ET.SubElement(source, \"database\").text = \"nuTonomy-nuscenes\"\n",
    "\n",
    "size = ET.SubElement(root, \"size\")\n",
    "ET.SubElement(size, \"width\").text=\"Katie\"\n",
    "ET.SubElement(size,\"height\").text=\"Kates\"\n",
    "ET.SubElement(size,\"depth\").text=\"KM\"\n",
    "ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "ob= ET.SubElement(root, \"object\")\n",
    "ET.SubElement(ob,\"name\").text=\"ball\"\n",
    "ET.SubElement(ob,\"pose\").text=\"Unspecified\"\n",
    "ET.SubElement(ob, \"truncated\").text=\"truncated\"\n",
    "ET.SubElement(ob, \"difficult\").text=\"0\"\n",
    "\n",
    "bb = ET.SubElement(ob,\"bndbox\")\n",
    "ET.SubElement(bb,\"xmin\").text=\"xmin\"\n",
    "ET.SubElement(bb,\"ymin\").text=\"ymin\"\n",
    "ET.SubElement(bb,\"xmax\").text=\"xmax\"\n",
    "ET.SubElement(bb,\"ymax\").text=\"ymax\"\n",
    "\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"%s.xml\" %name,pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open('images_with_no_annotations.txt') as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        \n",
    "        i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
